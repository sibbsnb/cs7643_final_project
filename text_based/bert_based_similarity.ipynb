{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e1ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_1: 0.021027863025665283, dist_2: 0.2777467966079712\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "from sent2vec.vectorizer import Vectorizer\n",
    "\n",
    "sentences = [\n",
    "    \"Paper Bag Victoria Secret\",\n",
    "    \"PAPER Bag Victoria Secret and something else\",\n",
    "    \"We can interchangeably use embedding, encoding, or vectorizing.\",\n",
    "]\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "vectorizer.bert(sentences)\n",
    "vectors_bert = vectorizer.vectors\n",
    "\n",
    "dist_1 = spatial.distance.cosine(vectors_bert[0], vectors_bert[1])\n",
    "dist_2 = spatial.distance.cosine(vectors_bert[0], vectors_bert[2])\n",
    "print('dist_1: {0}, dist_2: {1}'.format(dist_1, dist_2))\n",
    "# dist_1: 0.043, dist_2: 0.192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfba8f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sent2vec in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: torch in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from sent2vec) (1.7.1)\n",
      "Requirement already satisfied: spacy in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from sent2vec) (2.3.5)\n",
      "Requirement already satisfied: numpy in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from sent2vec) (1.19.2)\n",
      "Requirement already satisfied: transformers in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from sent2vec) (4.5.1)\n",
      "Requirement already satisfied: gensim in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from sent2vec) (4.0.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from gensim->sent2vec) (5.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from gensim->sent2vec) (1.6.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (0.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (2.0.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (7.4.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (3.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (4.59.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from spacy->sent2vec) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (2020.12.5)\n",
      "Requirement already satisfied: typing_extensions in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from torch->sent2vec) (3.7.4.3)\n",
      "Requirement already satisfied: sacremoses in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from transformers->sent2vec) (0.0.35)\n",
      "Requirement already satisfied: packaging in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from transformers->sent2vec) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from transformers->sent2vec) (2021.4.4)\n",
      "Requirement already satisfied: filelock in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from transformers->sent2vec) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from transformers->sent2vec) (0.10.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from packaging->transformers->sent2vec) (2.4.7)\n",
      "Requirement already satisfied: click in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from sacremoses->transformers->sent2vec) (7.1.2)\n",
      "Requirement already satisfied: six in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from sacremoses->transformers->sent2vec) (1.15.0)\n",
      "Requirement already satisfied: joblib in /Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages (from sacremoses->transformers->sent2vec) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sent2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fd1028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_1: 0.021027863025665283, dist_2: 0.2777467966079712\n"
     ]
    }
   ],
   "source": [
    "dist_1 = spatial.distance.cosine(vectors_bert[0], vectors_bert[1])\n",
    "dist_2 = spatial.distance.cosine(vectors_bert[0], vectors_bert[2])\n",
    "print('dist_1: {0}, dist_2: {1}'.format(dist_1, dist_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa841a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sibish/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494967a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>target</th>\n",
       "      <th>target_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>[train_129225211, train_2278313361]</td>\n",
       "      <td>train_129225211 train_2278313361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>[train_3386243561, train_3423213080]</td>\n",
       "      <td>train_3386243561 train_3423213080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "\n",
       "                                                          title  label_group  \\\n",
       "0                                     Paper Bag Victoria Secret    249114794   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE   2937985045   \n",
       "\n",
       "                                 target                      target_string  \n",
       "0   [train_129225211, train_2278313361]   train_129225211 train_2278313361  \n",
       "1  [train_3386243561, train_3423213080]  train_3386243561 train_3423213080  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "tmp = train_df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "train_df['target'] = train_df.label_group.map(tmp)\n",
    "train_df\n",
    "list = train_df[train_df['posting_id'] == 'train_129225211']['target'][0]\n",
    "list = ' '.join(list)\n",
    "list\n",
    "def target_string(list):\n",
    "    return ' '.join(list)\n",
    "    \n",
    "train_df['target_string'] = train_df.apply(lambda x: target_string(x['target']),axis=1)\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89198447",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_val = train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a38ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarity(sen1, sen2):\n",
    "    sentences = [sen1, sen2]\n",
    "    vectorizer.bert(sentences)\n",
    "    vectors_bert = vectorizer.vectors\n",
    "\n",
    "    dist_1 = spatial.distance.cosine(vectors_bert[0], vectors_bert[1])\n",
    "    #print(dist_1)\n",
    "    return dist_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3ae822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper Bag Victoria Secret\n",
      "matched:: Paper Bag Victoria Secret Paper Bag Victoria Secret 0.0\n",
      "matched:: Paper Bag Victoria Secret PIXY TWIN BLUSH 0.018628239631652832\n",
      "matched:: Paper Bag Victoria Secret Merries pants m34 0.01956188678741455\n",
      "matched:: Paper Bag Victoria Secret SAFFRON TONER 0.018972933292388916\n",
      "matched:: Paper Bag Victoria Secret RENATA DRESS 0.019744932651519775\n",
      "matched:: Paper Bag Victoria Secret RAYA LACE MAXY 0.018840432167053223\n",
      "matched:: Paper Bag Victoria Secret Sweater twist milky 0.019305884838104248\n",
      "matched:: Paper Bag Victoria Secret Sally knit cardy 0.019286155700683594\n",
      "matched:: Paper Bag Victoria Secret Pumpkin Ransel 0.01918870210647583\n",
      "matched:: Paper Bag Victoria Secret SCARLETT HAND SANITIZER 0.019877076148986816\n",
      "matched:: Paper Bag Victoria Secret Zara pants 0.018346309661865234\n",
      "matched:: Paper Bag Victoria Secret FROZEN DETOK 0.018355607986450195\n",
      "matched:: Paper Bag Victoria Secret Bubble Wrap Extra 0.019887030124664307\n",
      "matched:: Paper Bag Victoria Secret Dress wanita Malone 0.01845848560333252\n",
      "matched:: Paper Bag Victoria Secret BEATRICE MINIBAG 0.01752758026123047\n",
      "matched:: Paper Bag Victoria Secret Clairine Dress 0.01900780200958252\n",
      "matched:: Paper Bag Victoria Secret FACE SHIELD BABY 0.01828104257583618\n",
      "matched:: Paper Bag Victoria Secret ROLEX COUPLE 0.018208682537078857\n",
      "matched:: Paper Bag Victoria Secret Boxy Dress 0.01688748598098755\n",
      "matched:: Paper Bag Victoria Secret PINK NIGHT CREAM GLOW 0.01800018548965454\n",
      "matched:: Paper Bag Victoria Secret oversized LAVELLA cardigan 0.017792463302612305\n",
      "matched:: Paper Bag Victoria Secret Ring selfie 0.018419921398162842\n",
      "matched:: Paper Bag Victoria Secret Skinsena Glowing Facewash 0.019612431526184082\n",
      "matched:: Paper Bag Victoria Secret Merries pants M34 0.01956188678741455\n",
      "matched:: Paper Bag Victoria Secret snap on smile 0.018296480178833008\n",
      "matched:: Paper Bag Victoria Secret LIPSTICK SHANNEN CREAMY LIP 0.01596856117248535\n",
      "matched:: Paper Bag Victoria Secret Renata Dress 0.019744932651519775\n",
      "matched:: Paper Bag Victoria Secret PAPER BAG VICTORIA SECRET 0.0\n",
      "matched:: Paper Bag Victoria Secret Just Miss Eyebrow Pencil 311 0.01941359043121338\n",
      "matched  train_129225211 train_2106403674 train_2312596979 train_3159928461 train_1323699952 train_4135494872 train_3238013177 train_51240575 train_2435476985 train_3009849463 train_2053490150 train_1386324696 train_1454497638 train_1559794917 train_2693609978 train_3560214552 train_3714223252 train_804169090 train_145656700 train_1575354575 train_111808742 train_3663389447 train_3256377940 train_543385171 train_1365325916 train_800889804 train_3901996972 train_2278313361 train_2304073694\n",
      "Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages/pandas/core/indexing.py:1599: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "/Users/sibish/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched:: Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-21bc790b9e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcurrent_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_title\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matched::'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatch_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6af3f47f4b69>\u001b[0m in \u001b[0;36mfind_similarity\u001b[0;34m(sen1, sen2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msen1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvectors_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages/sent2vec/vectorizer.py\u001b[0m in \u001b[0;36mbert\u001b[0;34m(self, sentences, pretrained_weights)\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                             \u001b[0mppb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistilBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                             pretrained_weights)\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m                     resolved_vocab_files[file_id] = cached_path(\n\u001b[0m\u001b[1;32m   1663\u001b[0m                         \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m                         \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs7643-a2/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1386\u001b[0m                     )\n\u001b[1;32m   1387\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1389\u001b[0m                         \u001b[0;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m                         \u001b[0;34m\" Please try again or make sure your Internet connection is on.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "submission_df_val = pd.DataFrame()\n",
    "for match_index, match_row in train_df_val.iterrows():\n",
    "    print(match_row['title'])\n",
    "    match_title=match_row['title']\n",
    "    matched = \"\"\n",
    "    for index, row in train_df.iterrows():\n",
    "        current_title=row['title']\n",
    "        sim = find_similarity(match_title, current_title )\n",
    "        if sim < 0.02:\n",
    "            print('matched::',match_title, current_title, sim)\n",
    "            if len(matched)< 1:\n",
    "                matched = row['posting_id']\n",
    "            else:\n",
    "                matched = matched + \" \" + row['posting_id']\n",
    "    print(\"matched \", matched)    \n",
    "    #train_df_val.loc[match_index]['predicted'] = matched\n",
    "    train_df_val.loc[match_index,'predicted'] = matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95979733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(actual, predicted):\n",
    "    if actual == predicted:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "train_df_val['prediction_accuracy'] = train_df_val.apply(lambda x: match(x['target_string'], x['predicted']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06668dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy_v1 = train_df_val.groupby(['prediction_accuracy'])['posting_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "print(\"Accuracy of V3\" , (prediction_accuracy_v1[True]/(prediction_accuracy_v1[True] + prediction_accuracy_v1[False]))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fc5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a3",
   "language": "python",
   "name": "a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
